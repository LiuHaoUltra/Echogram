import re
import asyncio
import json
import time
from typing import List, Dict, Any, Optional
from sqlalchemy import select, text, and_, bindparam
from openai import AsyncOpenAI
from config.settings import settings
from config.database import get_db_session
from core.config_service import config_service
from models.history import History
from models.rag_status import RagStatus
from utils.logger import logger
import html

class RagService:
    # é»˜è®¤é…ç½®å¸¸é‡
    DEFAULT_SIMILARITY_THRESHOLD = 0.6
    DEFAULT_TOP_K = 5
    SYNC_COOLDOWN_SECONDS = 180  # 3åˆ†é’Ÿç†”æ–­å†·å´

    def __init__(self):
        self._client = None
        self._current_api_key = None
        self._current_base_url = None
        self._sync_cooldowns: Dict[int, float] = {}  # chat_id -> last_failure_time
    
    async def _get_client(self):
        """è·å–æˆ–åˆå§‹åŒ– OpenAI Client (æ”¯æŒåŠ¨æ€é…ç½®æ›´æ–°)"""
        configs = await config_service.get_all_settings()
        api_key = configs.get("api_key")
        base_url = configs.get("api_base_url")
        
        if not api_key:
             raise ValueError("API Key not configured")

        # æ£€æŸ¥é…ç½®æ˜¯å¦å˜æ›´
        if (not self._client or 
            api_key != self._current_api_key or 
            base_url != self._current_base_url):
            
            self._client = AsyncOpenAI(api_key=api_key, base_url=base_url)
            self._current_api_key = api_key
            self._current_base_url = base_url
            # logger.info("RAG Client (re)initialized with new config.")
            
        return self._client

    def sanitize_content(self, text: str) -> str:
        """
        æ¸…æ´—å†…å®¹ï¼š
        1. ä¼˜å…ˆæå– <chat> æ ‡ç­¾å†…çš„å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚
        2. å¦‚æœæ²¡æœ‰ <chat> æ ‡ç­¾ï¼ˆå¦‚ç”¨æˆ·æ¶ˆæ¯ï¼‰ï¼Œåˆ™é€€å›å¸¸è§„æ¸…æ´—ã€‚
        """
        if not text:
            return ""
            
        # 0. é¢„å¤„ç†
        
        # ç‰¹æ®Šå¤„ç† Image Summaryï¼Œä¿ç•™è¯­ä¹‰
        # [Image Summary: cute cat] -> å›¾ç‰‡å†…å®¹: cute cat
        text = re.sub(r'\[Image Summary\s*:(.*?)\]', r'å›¾ç‰‡å†…å®¹:\1', text, flags=re.IGNORECASE)

        # å»é™¤ç³»ç»Ÿå ä½ç¬¦ (é˜²æ­¢å™ªéŸ³è¿›å…¥å‘é‡åº“)
        placeholders = [
            "[Voice: Processing...]",
            "[Image: Processing...]"
        ]
        for ph in placeholders:
            text = text.replace(ph, "") 

        # 1. å°è¯•æå– <chat> æ ‡ç­¾å†…å®¹
        # æ³¨æ„: å†å²è®°å½•ä¸­çš„ chat æ ‡ç­¾å¯èƒ½åŒ…å«å±æ€§ (å¦‚ reply="123"), éœ€å…¼å®¹ <chat...>
        # å¯¹åº” SenderService ç”Ÿæˆæ ¼å¼: <chat reply="...">...</chat>
        chat_matches = re.findall(r'<chat[^>]*>(.*?)</chat>', text, flags=re.DOTALL | re.IGNORECASE)
        
        if chat_matches:
            # å¦‚æœå­˜åœ¨ <chat> æ ‡ç­¾ï¼Œåªä¿ç•™æ ‡ç­¾å†…çš„å†…å®¹
            # æ‹¼æ¥å¤šæ®µ chat å†…å®¹
            full_content = " ".join([m.strip() for m in chat_matches])
            return re.sub(r'\s+', ' ', full_content).strip()
            
        # 2. Fallback: å¦‚æœæ²¡æœ‰ <chat> æ ‡ç­¾ (å¸¸è§äº User æ¶ˆæ¯æˆ–æ—§æ•°æ®)
        # ä»ç„¶å»é™¤å¯èƒ½å­˜åœ¨çš„å…¶ä»– XML æ ‡ç­¾ä»¥é˜²å™ªéŸ³ï¼Œä½†ä¿ç•™æ–‡æœ¬
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    async def _embed_texts(self, texts: List[str]) -> List[List[float]]:
        """è°ƒç”¨ OpenAI API è·å– Embeddings"""
        if not texts:
            return []
            
        try:
            client = await self._get_client()
            configs = await config_service.get_all_settings()
            model_name = configs.get("vector_model_name", "text-embedding-3-small")

            resp = await client.embeddings.create(
                input=texts,
                model=model_name
            )
            
            # å¼ºè¡Œæˆªæ–­åˆ° 1536 ç»´
            # æ— è®ºæ¨¡å‹åŸç”Ÿç»´åº¦æ˜¯å¤šå°‘ï¼Œç»Ÿä¸€æˆªæ–­ä»¥é€‚é… sqlite-vec è¡¨ç»“æ„ã€‚
            # å¯¹äºæ”¯æŒ Matryoshka çš„æ¨¡å‹ï¼ˆå¦‚ OpenAI v3, Geminiï¼‰ï¼Œå‰ 1536 ç»´å³ä¸ºæœ‰æ•ˆè¡¨å¾ã€‚
            return [data.embedding[:1536] for data in resp.data]
        except Exception as e:
            logger.error(f"Embedding API failed: {e}")
            raise

    async def _check_and_migrate_status(self, session, chat_id: int):
        """
        [One-off Migration] è¿ç§»æ—§çš„çŠ¶æ€è¿½è¸ªæ–¹å¼ (Zero Vectors) åˆ°æ–°è¡¨ (rag_status)
        """
        try:
            # Check if already migrated (any record exists)
            count_res = await session.execute(
                text("SELECT 1 FROM rag_status WHERE chat_id=:cid LIMIT 1"), 
                {"cid": chat_id}
            )
            if count_res.scalar():
                return 

            # Check if legacy data exists
            legacy_count = await session.execute(
                text("SELECT COUNT(*) FROM history_vec v JOIN history h ON v.rowid=h.id WHERE h.chat_id=:cid"), 
                {"cid": chat_id}
            )
            if legacy_count.scalar() == 0:
                return

            logger.warning(f"RAG: Migrating chat {chat_id} to 'rag_status' table...")

            # 1. Identify Tails (Zero Vectors) -> Insert 'TAIL'
            # Use shotgun strategy to catch any zero vector format
            await session.execute(text("""
                INSERT INTO rag_status (msg_id, chat_id, status)
                SELECT v.rowid, :cid, 'TAIL'
                FROM history_vec v
                JOIN history h ON v.rowid = h.id
                WHERE h.chat_id = :cid
                  AND (v.embedding LIKE '[0.0, 0.0%' OR v.embedding LIKE '[0.0,0.0%' OR v.embedding LIKE '[0, 0%')
            """), {"cid": chat_id})

            # 2. Identify Heads (Real Vectors) -> Insert 'HEAD'
            # Any vector in DB that is NOT in rag_status yet must be a Head
            await session.execute(text("""
                INSERT INTO rag_status (msg_id, chat_id, status)
                SELECT v.rowid, :cid, 'HEAD'
                FROM history_vec v
                JOIN history h ON v.rowid = h.id
                WHERE h.chat_id = :cid
                  AND v.rowid NOT IN (SELECT msg_id FROM rag_status WHERE chat_id=:cid)
            """), {"cid": chat_id})

            # 3. Clean up Tails from history_vec (Free up space/indices)
            await session.execute(text("""
                DELETE FROM history_vec
                WHERE rowid IN (
                    SELECT msg_id FROM rag_status WHERE chat_id=:cid AND status='TAIL'
                )
            """), {"cid": chat_id})

            await session.commit()
            logger.info(f"RAG: Migration completed for chat {chat_id}")

        except Exception as e:
            logger.error(f"RAG Migration failed: {e}")
            # Do not re-raise, allow sync to proceed (fallback)

    async def sync_historic_embeddings(self, chat_id: int):
        """
        æ‡’æƒ°å…¨é‡åŒæ­¥ (Lazy Full-Sync) - Interaction-Centric Mode
        åªç´¢å¼• AI æ¶ˆæ¯ï¼Œå¹¶è‡ªåŠ¨èåˆå‰åºç”¨æˆ·é—®é¢˜ (User Context + AI Response)ã€‚
        """
        configs = await config_service.get_all_settings()
        
        # åŠ¨æ€è¯»å–å†·å´æ—¶é—´
        cooldown = self.SYNC_COOLDOWN_SECONDS
        try:
            if val := configs.get("rag_sync_cooldown"):
                cooldown = int(val)
        except: pass

        # 1. ç†”æ–­æ£€æŸ¥
        last_fail = self._sync_cooldowns.get(chat_id, 0)
        if time.time() - last_fail < cooldown:
            return

        async for session in get_db_session():
            try:
            try:
                # 0. Migration Check (Sync-time migration)
                await self._check_and_migrate_status(session, chat_id)

                # 2. æ‰¾å‡ºæ‰€æœ‰æœªåµŒå…¥çš„ AI æ¶ˆæ¯ (Anchors)
                # ä½¿ç”¨ rag_status åˆ¤æ–­æ˜¯å¦å·²å¤„ç†
                stmt = text("""
                    SELECT h.id, h.role, h.content 
                    FROM history h
                    LEFT JOIN rag_status s ON h.id = s.msg_id
                    WHERE h.chat_id = :chat_id 
                      AND h.role = 'assistant'
                      AND s.msg_id IS NULL
                      AND h.content IS NOT NULL
                      AND h.content != ''
                      AND h.content NOT LIKE '[%: Processing...]'
                    LIMIT 50
                """)
                
                result = await session.execute(stmt, {"chat_id": chat_id})
                ai_rows = result.fetchall()
                
                if not ai_rows:
                    if chat_id in self._sync_cooldowns:
                        del self._sync_cooldowns[chat_id]
                    return

                logger.info(f"RAG Sync: Found {len(ai_rows)} AI anchors for chat {chat_id}")

                # 3. Context Fusion Loop (Sequential Merging)
                db_write_ops = [] # list of (id, vector_or_placeholder)
                texts_to_embed = [] # list of strings
                text_map_indices = [] # indices in db_write_ops that need embedding filling
                
                processed_ids = set() # ids handled in this batch (as Head or Tail)

                for ai_row in ai_rows:
                    if ai_row.id in processed_ids:
                        continue
                    
                    # 3.1 Check Left Context (Is this a Tail?)
                    # Lookback 1 message
                    prev_sql = text("SELECT role FROM history WHERE chat_id = :cid AND id < :aid ORDER BY id DESC LIMIT 1")
                    prev_res = await session.execute(prev_sql, {"cid": chat_id, "aid": ai_row.id})
                    prev_row = prev_res.fetchone()
                    
                    is_tail = False
                    if prev_row and prev_row.role == 'assistant':
                        is_tail = True
                    
                    if is_tail:
                        # [Tail Strategy]
                        # è¿™æ˜¯ä¸€ä¸ª "æ‰é˜Ÿ" çš„åç»­æ°”æ³¡ (ä¸Šä¸€æ¡ä¹Ÿæ˜¯ AI)ã€‚
                        # å®ƒçš„å†…å®¹ç†åº”è¢«åˆå¹¶åœ¨ Head é‡Œã€‚
                        # å¦‚æœ Head å·²ç»ç´¢å¼•è¿‡ï¼Œæˆ‘ä»¬æ— æ³•è¿½æº¯æ›´æ–° Head (ä»£ä»·å¤ªå¤§)ã€‚
                        # æ‰€ä»¥ç­–ç•¥æ˜¯ï¼šç›´æ¥é™é»˜æ ‡è®°ä¸ºå·²å¤„ç† (Zero Vector)ï¼Œä¸ç”Ÿæˆç‹¬ç«‹ç´¢å¼• (é¿å…æ±¡æŸ“)ã€‚
                        processed_ids.add(ai_row.id)
                        db_write_ops.append((ai_row.id, "ZERO"))
                        continue

                    # [Head Strategy]
                    # è¿™æ˜¯ç”± User è§¦å‘çš„ç¬¬ä¸€æ¡ AI æ¶ˆæ¯ (Head)ã€‚
                    # æˆ‘ä»¬éœ€è¦å‘åç”±è´ªå©ªæŠ“å–æ‰€æœ‰è¿ç»­çš„ AI æ¶ˆæ¯ (Tails)ï¼Œåˆå¹¶å†…å®¹ã€‚
                    
                    # 3.2 Look Ahead (Find Consequent Tails)
                    # é™åˆ¶æŠ“å– 10 æ¡ï¼Œé¿å…æ— é™å¾ªç¯
                    next_sql = text("""
                        SELECT id, content, role FROM history 
                        WHERE chat_id = :cid AND id > :aid 
                        ORDER BY id ASC LIMIT 10
                    """)
                    next_res = await session.execute(next_sql, {"cid": chat_id, "aid": ai_row.id})
                    next_rows = next_res.fetchall()
                    
                    chain_content = [self.sanitize_content(ai_row.content)]
                    chain_ids = [ai_row.id]
                    
                    for nr in next_rows:
                        if nr.role == 'assistant':
                            # Found a tail
                            chain_content.append(self.sanitize_content(nr.content))
                            chain_ids.append(nr.id)
                        else:
                            # Met User/System -> Stop
                            break
                            
                    # Mark all as processed
                    for cid in chain_ids:
                        processed_ids.add(cid)
                        
                    # 3.3 Look Back (Get User Context)
                    # æŠ“å–æœ€è¿‘çš„ User æ¶ˆæ¯ (æœ€å¤š 3 æ¡è¿ç»­)
                    lb_sql = text("""
                        SELECT role, content FROM history 
                        WHERE chat_id = :cid AND id < :aid 
                        ORDER BY id DESC LIMIT 5
                    """)
                    lb_res = await session.execute(lb_sql, {"cid": chat_id, "aid": ai_row.id})
                    lb_rows = lb_res.fetchall()
                    
                    user_context_parts = []
                    for prev_msg in lb_rows:
                        if prev_msg.role == 'user':
                            prev_content = self.sanitize_content(prev_msg.content)
                            if prev_content:
                                user_context_parts.insert(0, prev_content)
                                if len(user_context_parts) >= 3: 
                                    break
                        else:
                            break
                            
                    # 3.4 Build Fused Text
                    merged_ai_content = " ".join([c for c in chain_content if c])
                    
                    fused_text = ""
                    if user_context_parts:
                        user_block = " ".join(user_context_parts)
                        fused_text = f"User: {user_block}\nAssistant: {merged_ai_content}"
                    else:
                        fused_text = f"Assistant: {merged_ai_content}"
                    
                    # Register for embedding
                    texts_to_embed.append(fused_text)
                    
                    # Head gets the vector
                    db_write_ops.append((ai_row.id, "PENDING")) 
                    text_map_indices.append(len(db_write_ops) - 1)
                    
                    # Tails get ZERO
                    for tail_id in chain_ids[1:]:
                        db_write_ops.append((tail_id, "ZERO"))

                if not db_write_ops:
                    return

                # 4. Batch Embed
                embeddings = []
                if texts_to_embed:
                    embeddings = await self._embed_texts(texts_to_embed)
                
                # Fill PENDING with vectors
                real_vectors_map = {idx: vec for idx, vec in zip(text_map_indices, embeddings)}
                
                # 5. [DEBUG] Notification
                try:
                    import core.bot as bot_module
                    if bot_module.bot and texts_to_embed:
                        # æ„å»ºå®Œæ•´é¢„è§ˆ (Max 3500 chars)
                        full_preview = ""
                        for idx, item in enumerate(texts_to_embed):
                            snippet = item.split('\n')[0][:50] + "..." if len(item) > 100 else item
                            full_preview += f"[{idx+1}] {html.escape(snippet)}\n"
                        
                        if len(full_preview) > 3500:
                            full_preview = full_preview[:3500] + "\n... (Truncated)"

                        debug_msg = (
                            f"ğŸ”® <b>RAG Sync: Interaction Mode</b>\n"
                            f"Chat: <code>{chat_id}</code> | Turns: <code>{len(texts_to_embed)}</code> (Merged)\n"
                            f"<pre>{full_preview}</pre>"
                        )
                        await bot_module.bot.send_message(settings.ADMIN_USER_ID, debug_msg, parse_mode='HTML')
                except: pass

                # 6. Write to DB
                # PENDING -> Head (Vector + Status)
                # ZERO -> Tail (Status Only)
                
                for i, (mid, status) in enumerate(db_write_ops):
                    final_vec = None
                    rag_status_val = "TAIL"
                    
                    if status == "PENDING":
                        # Find mapped vector
                        if i in real_vectors_map:
                            final_vec = real_vectors_map[i]
                            rag_status_val = "HEAD"
                    
                    # 1. Update Status Table (Always)
                    # Note: Using INSERT OR IGNORE just in case concurrency
                    await session.execute(
                        text("INSERT OR IGNORE INTO rag_status (msg_id, chat_id, status) VALUES (:id, :cid, :status)"),
                        {"id": mid, "cid": chat_id, "status": rag_status_val}
                    )
                        
                    # 2. Insert Vector (Only if Head/Real)
                    if final_vec:
                        await session.execute(
                            text("INSERT INTO history_vec(rowid, embedding) VALUES (:id, :embedding)"),
                            {"id": mid, "embedding": json.dumps(final_vec)} 
                        )
                
                await session.commit()
                logger.info(f"RAG Sync: Indexed {len(texts_to_embed)} Heads, Skipped {len(db_write_ops) - len(texts_to_embed)} Tails.")
                
                if chat_id in self._sync_cooldowns:
                    del self._sync_cooldowns[chat_id]
            except Exception as e:
                logger.error(f"RAG Sync failed for chat {chat_id}: {e}")
                self._sync_cooldowns[chat_id] = time.time()

    async def contextualize_query(self, query_text: str, conversation_history: str, long_term_summary: str = "") -> str:
        """
        [Query Rewriting]
        ä½¿ç”¨æ‘˜è¦æ¨¡å‹å¿«é€Ÿé‡å†™æŸ¥è¯¢ï¼Œæ¶ˆé™¤æŒ‡ä»£ä¸æ˜ã€‚
        ç°åœ¨æ¥æ”¶ä¸ä¸»æ¨¡å‹å®Œå…¨ä¸€è‡´çš„ Full Context (Active Window + Summary)ã€‚
        """
        # [DEBUG] Log entry
        logger.info(f"RAG Rewriter: Input='{query_text}' (Len: {len(query_text)})")

        # ç®€å•å¯å‘å¼è¿‡æ»¤ï¼šå¦‚æœå¾ˆé•¿ï¼Œå¯èƒ½ä¸éœ€è¦é‡å†™ (çœé’±)
        if len(query_text) > 40:
            logger.info("RAG Rewriter: Skipped (Length > 40)")
            return query_text

        try:
            configs = await config_service.get_all_settings()
            summary_model = configs.get("summary_model_name")
            
            # å¦‚æœæ²¡é…æ‘˜è¦æ¨¡å‹ï¼Œåˆ™é™çº§ä½¿ç”¨ä¸»æ¨¡å‹ï¼›å¦‚æœä¸»æ¨¡å‹ä¹Ÿæ²¡é…ï¼Œåˆ™è·³è¿‡
            if not summary_model:
                summary_model = configs.get("model_name")
            
            if not summary_model:
                logger.warning("RAG Rewriter: Skipped (No Model Configured)")
                return query_text

            logger.info(f"RAG Rewriter: Using model '{summary_model}'")

            client = await self._get_client()
            
            # æ„å»ºè½»é‡çº§ Context
            # context_msgs åº”è¯¥æ˜¯ ["User: ...", "Assistant: ..."] çš„æœ€è¿‘å‡ æ¡
            sys_prompt = (
                "ä½ æ˜¯ä¸€åæŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚"
                "ä½ çš„ç›®æ ‡æ˜¯å°†ç”¨æˆ·çš„æœ€æ–°è¾“å…¥é‡å†™ä¸ºé€‚åˆæ•°æ®åº“æ£€ç´¢çš„ç®€æ´æŸ¥è¯¢è¯­å¥ã€‚"
                "1. æŒ‡ä»£æ¶ˆæ­§ï¼šå°†'å®ƒ'ã€'é‚£ä¸ª'ç­‰ä»£è¯æ›¿æ¢ä¸ºä¸Šä¸‹æ–‡ä¸­è®¨è®ºçš„å…·ä½“å¯¹è±¡ã€‚"
                "2. è¡¥å……èƒŒæ™¯ï¼šå¦‚æœç”¨æˆ·çš„è¯ä¾èµ–å‰æ–‡ï¼ˆå¦‚è¿½é—®åŸå› ï¼‰ï¼Œè¯·æŠŠä¸»è¯­å’ŒèƒŒæ™¯è¡¥å…¨ã€‚"
                "3. å»å™ªç²¾ç®€ï¼šåšå†³å»é™¤æ‰€æœ‰æƒ…ç»ªè¯ï¼ˆå¦‚'å“æ­»'ã€'å“ˆå“ˆ'ï¼‰ã€å£è¯­åºŸè¯ï¼ˆå¦‚'æˆ‘æƒ³æƒ³'ã€'ä¸çŸ¥é“'ï¼‰å’ŒæŠ±æ€¨ã€‚åªä¿ç•™äº‹å®æ€§å…³é”®è¯ã€‚"
                "4. è¾“å‡ºæ ¼å¼ï¼šè¾“å‡ºä¸€å¥æ¸…æ™°ã€å®¢è§‚çš„é™ˆè¿°å¥æˆ–é—®å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚"
                "åªè¾“å‡ºé‡å†™åçš„å­—ç¬¦ä¸²ã€‚"
            )
            
            # Construct Rich Context Block
            full_context_block = ""
            if long_term_summary:
                full_context_block += f"=== Long-term Memory ===\n{long_term_summary}\n\n"
            
            full_context_block += f"=== Active Conversation ===\n{conversation_history}"

            resp = await client.chat.completions.create(
                model=summary_model,
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": f"{full_context_block}\n\nUser Input to Rewrite:\n{query_text}"}
                ],
                max_tokens=200,
                temperature=0.3
            )
            
            if resp.choices and resp.choices[0].message.content:
                new_query = resp.choices[0].message.content.strip()
                # ç§»é™¤å¯èƒ½è¯¯å¸¦çš„å¼•å·
                if new_query.startswith('"') and new_query.endswith('"'):
                    new_query = new_query[1:-1]
                
                if new_query != query_text:
                    logger.info(f"RAG Rewriter: '{query_text}' -> '{new_query}'")
                    try:
                        import core.bot as bot_module
                        if bot_module.bot:
                            rewrite_msg = (
                                f"ğŸ”„ <b>RAG Query Rewritten</b>\n"
                                f"From: <code>{html.escape(query_text)}</code>\n"
                                f"To: <code>{html.escape(new_query)}</code>"
                            )
                            await bot_module.bot.send_message(settings.ADMIN_USER_ID, rewrite_msg, parse_mode='HTML')
                    except Exception as notify_e:
                        logger.error(f"Failed to send rewrite debug: {notify_e}")
                else:
                    logger.info(f"RAG Rewriter: No change ('{new_query}').")
                
                return new_query
            
        except Exception as e:
            logger.warning(f"Query Rewrite failed: {e}")
            
        return query_text

    async def search_context(self, chat_id: int, query_text: str, exclude_ids: Optional[List[int]] = None, top_k: int = 5, context_padding: int = 3) -> str:
        """
        æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ (Context Window Expansion)
        
        ç­–ç•¥:
        1. Vector Search: æ‰¾åˆ° Top K æ ¸å¿ƒåŒ¹é… (Anchors).
        2. Expansion: å¯¹æ¯ä¸ª Anchorï¼ŒåŸºäºé€»è¾‘é¡ºåºæŸ¥è¯¢å‰åæ–‡ (è§£å†³ ID Gap é—®é¢˜).
        3. Clustering: åˆå¹¶é‡å çš„ä¸Šä¸‹æ–‡çª—å£.
        4. Formatting: è¾“å‡ºå¸¦ç„¦ç‚¹çš„å¯¹è¯å—.

        :param exclude_ids: éœ€è¦æ’é™¤çš„æ¶ˆæ¯ ID åˆ—è¡¨ (é¿å…è‡ªå¼•ç”¨)
        :param context_padding: æ¯ä¸ª Anchor å‰åæ‰©å±•çš„æ¶ˆæ¯æ•°é‡
        """
        sanitized_query = self.sanitize_content(query_text)
        if len(sanitized_query) < 2:
            return ""

        limit = top_k if top_k else self.DEFAULT_TOP_K
        
        configs = await config_service.get_all_settings()
        
        # åŠ¨æ€è¯»å– Padding é…ç½®
        current_padding = context_padding
        try:
            if val := configs.get("rag_context_padding"):
                current_padding = int(val)
        except: pass
        
        threshold = self.DEFAULT_SIMILARITY_THRESHOLD
        try:
            if val := configs.get("rag_similarity_threshold"):
                threshold = float(val)
        except: pass

        # [DEBUG] Start Notification
        try:
            import core.bot as bot_module
            if bot_module.bot:
                start_msg = (
                    f"ğŸ” <b>RAG Search: Interaction Mode</b>\n"
                    f"Chat: <code>{chat_id}</code> | Q: <code>{html.escape(sanitized_query)}</code>\n"
                    f"TopK: {limit} | Pad: {current_padding}"
                )
                await bot_module.bot.send_message(settings.ADMIN_USER_ID, start_msg, parse_mode='HTML')
        except: pass

        try:
            # 1. Get Query Vector
            query_vecs = await self._embed_texts([sanitized_query])
            if not query_vecs:
                print(f"[DEBUG] No query vector generated", file=sys.stderr)
                return ""
            query_vec = query_vecs[0]
            
            async for session in get_db_session():
                # ---------------------------------------------------------
                # Step 1: Vector Search (Find Anchors)
                # ---------------------------------------------------------
                exclusion_clause = ""
                params = {
                    "chat_id": chat_id, 
                    "query_vec": json.dumps(query_vec),
                    "threshold": threshold,
                    "top_k": limit
                }
                
                if exclude_ids:
                    exclusion_clause = "AND h.id NOT IN :exclude_ids"
                    params["exclude_ids"] = tuple(exclude_ids)

                anchor_sql = f"""
                    SELECT h.id, vec_distance_cosine(v.embedding, :query_vec) as distance
                    FROM history_vec v
                    JOIN history h ON v.rowid = h.id
                    WHERE h.chat_id = :chat_id 
                      AND vec_distance_cosine(v.embedding, :query_vec) < :threshold
                      {exclusion_clause}
                    ORDER BY distance ASC
                    LIMIT :top_k
                """
                
                stmt = text(anchor_sql)
                if exclude_ids:
                    stmt = stmt.bindparams(bindparam("exclude_ids", expanding=True))
                
                result = await session.execute(stmt, params)
                anchors = result.fetchall()  # [(id, distance), ...]
                
                if not anchors:
                    return ""
                
                anchor_map = {row.id: row.distance for row in anchors}
                sorted_anchor_ids = [row.id for row in anchors]

                # ---------------------------------------------------------
                # Step 2: Logical Expansion (Fixing ID Gaps)
                # ---------------------------------------------------------
                # Clusters: List[Set[int]] - åˆå§‹æ¯ä¸ª Anchor ä¸€ä¸ª Cluster
                clusters: List[set] = []

                for anchor_id in sorted_anchor_ids:
                    # è·å–å‰æ–‡ (Pre-context)
                    # å€’åºå– limitï¼Œç»“æœéœ€åè½¬
                    pre_sql = text("""
                        SELECT id FROM history 
                        WHERE chat_id = :cid AND id < :aid 
                        ORDER BY id DESC LIMIT :pad
                    """)
                    pre_res = await session.execute(pre_sql, {"cid": chat_id, "aid": anchor_id, "pad": current_padding})
                    pre_ids = [r.id for r in pre_res.fetchall()]
                    
                    # è·å–åæ–‡ (Post-context)
                    post_sql = text("""
                        SELECT id FROM history 
                        WHERE chat_id = :cid AND id > :aid 
                        ORDER BY id ASC LIMIT :pad
                    """)
                    post_res = await session.execute(post_sql, {"cid": chat_id, "aid": anchor_id, "pad": current_padding})
                    post_ids = [r.id for r in post_res.fetchall()]




                    # ç»„è£…å½“å‰ Cluster
                    current_cluster = set(pre_ids + [anchor_id] + post_ids)
                    clusters.append(current_cluster)

                # ---------------------------------------------------------
                # Step 3: Cluster Merging
                # ---------------------------------------------------------
                # è´ªå©ªåˆå¹¶ï¼šå¦‚æœæœ‰äº¤é›†ï¼Œåˆ™åˆå¹¶
                merged_clusters: List[set] = []
                
                while clusters:
                    base = clusters.pop(0)
                    # å°è¯•ä¸åç»­æ‰€æœ‰ cluster åˆå¹¶
                    i = 0
                    while i < len(clusters):
                        candidate = clusters[i]
                        if not base.isdisjoint(candidate):
                            base.update(candidate)
                            clusters.pop(i) # ç§»é™¤å·²è¢«åˆå¹¶çš„
                        else:
                            i += 1
                    merged_clusters.append(base)

                # ---------------------------------------------------------
                # Step 4: Content Fetching
                # ---------------------------------------------------------
                # æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„ Unique ID
                all_needed_ids = set()
                for c in merged_clusters:
                    all_needed_ids.update(c)
                
                if not all_needed_ids:
                    return ""

                # æ‰¹é‡è·å–å†…å®¹
                fetch_sql = text("SELECT id, role, content, timestamp FROM history WHERE id IN :ids")
                fetch_stmt = fetch_sql.bindparams(bindparam("ids", expanding=True))
                fetch_res = await session.execute(fetch_stmt, {"ids": tuple(all_needed_ids)})
                
                # ID -> Message Object
                msg_map = {
                    row.id: {
                        "role": row.role,
                        "content": row.content,
                        "timestamp": row.timestamp
                    } 
                    for row in fetch_res.fetchall()
                }

                # ---------------------------------------------------------
                # Step 5: Formatting with Focus Highlighting
                # ---------------------------------------------------------
                output_blocks = []
                
                # å¯¹ Merged Clusters æŒ‰å…¶ä¸­æœ€å° ID æ’åºï¼Œä¿è¯æ—¶é—´åº
                merged_clusters.sort(key=lambda s: min(s))

                for cluster in merged_clusters:
                    # Cluster å†…éƒ¨æŒ‰ ID æ’åº
                    sorted_ids = sorted(list(cluster))
                    block_lines = []
                    
                    for mid in sorted_ids:
                        msg = msg_map.get(mid)
                        if not msg: continue
                        
                        # Date Formatting
                        date_str = "Unknown"
                        if msg["timestamp"]:
                            if hasattr(msg["timestamp"], 'strftime'):
                                date_str = msg["timestamp"].strftime("%Y-%m-%d %H:%M")
                            else:
                                date_str = str(msg["timestamp"])[:16]

                        content = self.sanitize_content(msg["content"])
                        line = f"[{date_str}] {msg['role'].capitalize()}: {content}"

                        # Check if this is an Anchor
                        if mid in anchor_map:
                            dist = anchor_map[mid]
                            # Highlight Anchor
                            line = f">>> {line} (Match: {dist:.3f}) <<<"
                        
                        block_lines.append(line)
                    
                    output_blocks.append("\n".join(block_lines))

                # Join blocks with explicit separator
                final_context = "\n\n... (Context Skip) ...\n\n".join(output_blocks)

                # [DEBUG] Success Notification
                try:
                    import core.bot as bot_module
                    if bot_module.bot:
                        debug_msg = (
                            f"âœ… <b>RAG Result: Interaction Mode</b>\n"
                            f"Blocks: {len(output_blocks)} | Total Msgs: {len(all_needed_ids)}\n"
                            f"<pre>{html.escape(final_context[:3000])}</pre>" # Truncate for TG
                        )
                        await bot_module.bot.send_message(settings.ADMIN_USER_ID, debug_msg, parse_mode='HTML')
                except: pass

                return final_context

        except Exception as e:
            logger.error(f"RAG Search failed: {e}", exc_info=True)
            return ""

    async def clear_chat_vectors(self, chat_id: int):
        """
        æ¸…é™¤æŒ‡å®šä¼šè¯çš„æ‰€æœ‰å‘é‡æ•°æ® (ç‰©ç†åˆ é™¤)
        ç”¨äº /reset æˆ– Rebuild Index
        """
        async for session in get_db_session():
            try:
                # é€šè¿‡å­æŸ¥è¯¢åˆ é™¤ history_vec ä¸­å¯¹åº”çš„ rowid
                # å‡è®¾ history_vec æ˜¯è™šæ‹Ÿè¡¨æˆ–æ™®é€šè¡¨ï¼Œrowid å¯¹åº” history.id
                await session.execute(
                    text("""
                        DELETE FROM history_vec 
                        WHERE rowid IN (
                            SELECT id FROM history WHERE chat_id = :chat_id
                        )
                    """),
                    {"chat_id": chat_id}
                )
                await session.commit()
                
                # æ¸…é™¤å†·å´çŠ¶æ€ï¼Œå…è®¸ç«‹å³é‡æ–°åŒæ­¥
                if chat_id in self._sync_cooldowns:
                    del self._sync_cooldowns[chat_id]
                    
                logger.info(f"RAG: Cleared all vectors for chat {chat_id}")
            except Exception as e:
                logger.error(f"RAG Clear failed for chat {chat_id}: {e}")

    async def clear_all_vectors(self):
        """
        [Danger] æ¸…é™¤æ•´ä¸ªæ•°æ®åº“çš„æ‰€æœ‰å‘é‡ç´¢å¼•
        ç”¨äºåˆ‡æ¢ Embedding æ¨¡å‹æ—¶çš„å…¨å±€é‡å»º
        """
        async for session in get_db_session():
            try:
                await session.execute(text("DELETE FROM history_vec"))
                await session.commit()
                
                # æ¸…é™¤æ‰€æœ‰å†·å´
                self._sync_cooldowns.clear()
                
                logger.warning("RAG: GLOBALLY CLEARED all vector indices!")
            except Exception as e:
                logger.error(f"RAG Global Clear failed: {e}")

    async def rebuild_index(self, chat_id: int = None):
        """
        Rebuild Index
        å¦‚æœæŒ‡å®š chat_idï¼Œåªæ¸…é™¤è¯¥ä¼šè¯ã€‚
        å¦‚æœä¸æŒ‡å®š (None)ï¼Œåˆ™æ¸…é™¤æ‰€æœ‰ (Global).
        """
        if chat_id:
            await self.clear_chat_vectors(chat_id)
        else:
            await self.clear_all_vectors()

    async def get_vector_stats(self, chat_id: int) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šä¼šè¯çš„å‘é‡ç´¢å¼•ç»Ÿè®¡
        """
        async for session in get_db_session():
            try:
                # ç»Ÿè®¡ï¼š
                # 1. Total Eligible Heads: ä»…ç»Ÿè®¡ "Head" (å‰ä¸€æ¡ä¸æ˜¯ AI çš„ AI æ¶ˆæ¯)
                # 2. Indexed Heads: ä»…ç»Ÿè®¡é Zero Vector çš„ç´¢å¼•
                
                # æ„é€  Zero Vector JSON å­—ç¬¦ä¸²ç”¨äºæ’é™¤
                zero_vec_json = json.dumps([0.0] * 1536)
                
                # SQLite å¤æ‚ç»Ÿè®¡ (Count Heads)
                # ä½¿ç”¨åµŒå¥—æŸ¥è¯¢åˆ¤æ–­ "Is Head"
                # (h.role='assistant' AND (prev.role IS NULL OR prev.role != 'assistant'))
                
                # Total Heads (åˆ†æ¯)
                stmt_total = text("""
                    SELECT COUNT(*) FROM history h
                    WHERE h.chat_id = :chat_id 
                      AND h.role = 'assistant'
                      AND h.content IS NOT NULL
                      AND h.content != ''
                      AND h.content NOT LIKE '[%: Processing...]'
                      AND (
                          SELECT role FROM history prev 
                          WHERE prev.chat_id = :chat_id AND prev.id < h.id 
                          ORDER BY prev.id DESC LIMIT 1
                      ) IS NOT 'assistant'
                """)
                
                # Indexed Heads (åˆ†å­)
                # ä½¿ç”¨ rag_status è¡¨ç»Ÿè®¡ (Status='HEAD')
                # è¿™ä»£è¡¨çœŸæ­£äº§ç”Ÿå‘é‡å¹¶å·²è¢«ç´¢å¼•çš„æ¶ˆæ¯
                stmt_indexed = text("""
                    SELECT COUNT(*) FROM rag_status
                    WHERE chat_id = :chat_id AND status = 'HEAD'
                """)
                
                # Execute
                res_total = await session.execute(stmt_total, {"chat_id": chat_id})
                total = res_total.scalar() or 0
                
                res_indexed = await session.execute(stmt_indexed, {"chat_id": chat_id})
                indexed = res_indexed.scalar() or 0
                
                # æ£€æŸ¥å†·å´çŠ¶æ€
                cooldown_left = 0
                if chat_id in self._sync_cooldowns:
                     passed = time.time() - self._sync_cooldowns[chat_id]
                     if passed < self.SYNC_COOLDOWN_SECONDS:
                         cooldown_left = int(self.SYNC_COOLDOWN_SECONDS - passed)
                
                return {
                    "total_eligible": total,
                    "indexed": indexed,
                    "cooldown_left": cooldown_left
                }
            except Exception as e:
                logger.error(f"RAG Stats failed: {e}")
                return {"error": str(e)}

rag_service = RagService()
