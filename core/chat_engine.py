from telegram import Update, constants
from telegram.ext import ContextTypes
from openai import AsyncOpenAI
import re
import asyncio
import pytz

from core.access_service import access_service
from core.history_service import history_service
from core.config_service import config_service
from core.summary_service import summary_service
from config.settings import settings
from config.database import get_db_session
from models.history import History
from sqlalchemy import select, delete
from core.secure import is_admin
from core.lazy_sender import lazy_sender
from core.media_service import media_service, TTSNotConfiguredError, MediaServiceError
from utils.logger import logger
from utils.prompts import prompt_builder
from utils.config_validator import safe_int_config, safe_float_config
from core.sender_service import sender_service
from core.rag_service import rag_service
from collections import defaultdict

# ä¼šè¯çº§ RAG é”ï¼Œé˜²æ­¢å¹¶å‘å¯¼è‡´é‡å¤åµŒå…¥
CHAT_LOCKS = defaultdict(asyncio.Lock)


async def process_message_entry(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    HTTP/Telegram æ¶ˆæ¯å…¥å£ (æ–‡æœ¬)
    1. é‰´æƒ
    2. å­˜å…¥å†å²
    3. æ”¾å…¥ç¼“å†²é˜Ÿåˆ— (LazySender)
    """
    user = update.effective_user
    chat = update.effective_chat
    message = update.message
    
    # ç©ºå€¼æ£€æŸ¥ï¼šuserã€chatã€message å¿…é¡»å­˜åœ¨
    if not user or not chat or not message or not message.text:
        return
        
    # æŒ‡ä»¤äº¤ç”± CommandHandler å¤„ç†
    if message.text.strip().startswith('/'):
        return

    # --- 1. è®¿é—®æ§åˆ¶ ---
    is_adm = is_admin(user.id)
    
    if chat.type == constants.ChatType.PRIVATE:
        # ç§èŠï¼šä»…ç®¡ç†å‘˜å¯è§ï¼Œä½†ä¸ä½œä¸ºèŠå¤©è®°å½•å¤„ç†
        if is_adm:
            pass
        return
    else:
        # ç¾¤ç»„ï¼šå¿…é¡»åœ¨ç™½åå•å†…
        if not await access_service.is_whitelisted(chat.id):
            return
            
    # é€šè¿‡é‰´æƒåè®°å½•æ—¥å¿—
    logger.info(f"MSG [{chat.id}] from {user.first_name}: {message.text[:20]}...")

    # å­˜å…¥å†å²
    reply_to_id = None
    reply_to_content = None
    
    if message.reply_to_message:
        reply_to_id = message.reply_to_message.message_id
        raw_ref_text = message.reply_to_message.text or "[Non-text message]"
        reply_to_content = (raw_ref_text[:30] + "..") if len(raw_ref_text) > 30 else raw_ref_text

    await history_service.add_message(
        chat.id, 
        "user", 
        message.text, 
        message_id=message.message_id,
        reply_to_id=reply_to_id,
        reply_to_content=reply_to_content
    )
    
    await lazy_sender.on_message(chat.id, context)

    try:
        asyncio.create_task(summary_service.check_and_summarize(chat.id))
    except Exception as e:
        logger.error(f"Failed to trigger proactive summary: {e}")


async def process_photo_entry(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    å›¾ç‰‡æ¶ˆæ¯å…¥å£ (èšåˆæ¨¡å¼)
    """
    user = update.effective_user
    chat = update.effective_chat
    message = update.message
    
    if not user or not chat or not message or not message.photo:
        return
        
    # --- 1. è®¿é—®æ§åˆ¶ ---
    is_adm = is_admin(user.id)
    if chat.type == constants.ChatType.PRIVATE:
        if is_adm: pass
        return
    else:
        if not await access_service.is_whitelisted(chat.id):
            return
            
    logger.info(f"PHOTO [{chat.id}] from {user.first_name}")
    
    # è·å–æœ€å¤§å°ºå¯¸å›¾ç‰‡
    photo = message.photo[-1]
    file_id = photo.file_id
    
    # å­˜å…¥å†å² (å ä½)
    reply_to_id = None
    reply_to_content = None
    if message.reply_to_message:
        reply_to_id = message.reply_to_message.message_id
        raw_text = message.reply_to_message.text or "[Non-text message]"
        reply_to_content = (raw_text[:30] + "..") if len(raw_text) > 30 else raw_text

    # è·å– Caption 
    caption = message.caption or ""
    db_content = f"[Image: Processing...]{caption}"

    await history_service.add_message(
        chat.id, "user", db_content, 
        message_id=message.message_id,
        reply_to_id=reply_to_id, reply_to_content=reply_to_content,
        message_type="image", file_id=file_id
    )
    
    # è§¦å‘èšåˆ
    await lazy_sender.on_message(chat.id, context)
    try:
        asyncio.create_task(summary_service.check_and_summarize(chat.id))
    except:
        pass


async def process_voice_message_entry(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    è¯­éŸ³æ¶ˆæ¯å…¥å£ (èšåˆæ¨¡å¼)
    """
    user = update.effective_user
    chat = update.effective_chat
    message = update.message
    
    # ç©ºå€¼æ£€æŸ¥
    if not user or not chat or not message or not message.voice:
        return
    
    # --- 1. è®¿é—®æ§åˆ¶ ---
    is_adm = is_admin(user.id)
    if chat.type == constants.ChatType.PRIVATE:
        if is_adm: pass
        return
    else:
        if not await access_service.is_whitelisted(chat.id):
            return
    
    logger.info(f"VOICE [{chat.id}] from {user.first_name}: {message.voice.duration}s")
    
    file_id = message.voice.file_id
    
    # å­˜å…¥å†å² (å ä½)
    reply_to_id = None
    reply_to_content = None
    if message.reply_to_message:
        reply_to_id = message.reply_to_message.message_id
        raw_text = message.reply_to_message.text or "[Non-text message]"
        reply_to_content = (raw_text[:30] + "..") if len(raw_text) > 30 else raw_text

    await history_service.add_message(
        chat.id, "user", "[Voice: Processing...]",
        message_id=message.message_id,
        reply_to_id=reply_to_id, reply_to_content=reply_to_content,
        message_type="voice", file_id=file_id
    )
    
    # è§¦å‘èšåˆ
    await lazy_sender.on_message(chat.id, context)
    try:
        asyncio.create_task(summary_service.check_and_summarize(chat.id))
    except:
        pass


async def generate_response(chat_id: int, context: ContextTypes.DEFAULT_TYPE):
    """
    æ ¸å¿ƒå›å¤ç”Ÿæˆé€»è¾‘ (æ”¯æŒå¤šæ¨¡æ€èšåˆ)
    1. è·å–å†å²
    2. æ‰«æ Recent Assistant ä¹‹åçš„ User Messages
    3. æå– pending çš„å›¾ç‰‡/è¯­éŸ³å¹¶ä¸‹è½½è½¬æ¢
    4. æ„é€  Multimodal Payload
    5. è°ƒç”¨ LLM
    6. è§£æç»“æœ (Summary/Transcript) å¹¶å›å¡« DB
    7. å‘é€å›å¤
    """
    logger.info(f"Generate Response triggered for Chat {chat_id}")
    
    configs = await config_service.get_all_settings()
    api_key = configs.get("api_key")
    base_url = configs.get("api_base_url")
    model = configs.get("model_name", "gpt-3.5-turbo")
    system_prompt_custom = configs.get("system_prompt")
    timezone = configs.get("timezone", "UTC")

    if not api_key:
        await context.bot.send_message(chat_id, "âš ï¸ å°šæœªé…ç½® API Keyï¼Œè¯·ä½¿ç”¨ /dashboard é…ç½®ã€‚")
        return

    dynamic_summary = await summary_service.get_summary(chat_id)

    # --- RAG Integration & Core Locking ---
    # æŒ‰ç…§æŒ‡ç¤ºï¼Œæ•´ä¸ªç”Ÿæˆè¿‡ç¨‹éœ€è¦åœ¨é”å†…æ‰§è¡Œï¼Œä»¥ä¿è¯ Strict Serialization
    async with CHAT_LOCKS[chat_id]:
        rag_context = ""
        try:
            # 1. è´ªå©ªè¡¥å½• (Lazy Full-Sync)
            # åªè¦è¿›æ¥äº†ï¼Œå°±é¡ºä¾¿æŠŠè¯¥ç¾¤æ¬ çš„å€ºå…¨è¡¥ä¸Š
            await rag_service.sync_historic_embeddings(chat_id)
        except Exception as e:
            logger.error(f"RAG Sync Error: {e}")

        # Token limit check
        target_tokens = safe_int_config(
            configs.get("history_tokens"),
            settings.HISTORY_WINDOW_TOKENS,
            min_val=100, max_val=50000
        )
        
        # 1. è·å–åŸºç¡€å†å²è®°å½•
        history_msgs = await history_service.get_token_controlled_context(chat_id, target_tokens=target_tokens)
        
        # 2. è¯†åˆ«â€œå°¾éƒ¨â€èšåˆåŒºé—´ 
        last_assistant_idx = -1
        for i in range(len(history_msgs) - 1, -1, -1):
            if history_msgs[i].role == 'assistant':
                last_assistant_idx = i
                break
                
        if last_assistant_idx == -1:
            tail_msgs = history_msgs
            base_msgs = []
        else:
            base_msgs = history_msgs[:last_assistant_idx+1]
            tail_msgs = history_msgs[last_assistant_idx+1:]
    
        # --- RAG Search ---
        # ç§»åˆ°é”å†…æ‰§è¡Œï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„ embeddings
        try:
            current_query = ""
            for m in reversed(tail_msgs):
                # å¯»æ‰¾æœ€è¿‘ä¸€æ¡ä¸”ä¸æ˜¯å ä½ç¬¦çš„ User Message
                if m.role == 'user' and m.content and not m.content.startswith("["):
                     current_query = m.content
                     break
            
            if current_query:
                # æ”¶é›†å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ ID ä»¥æ’é™¤ (Self-Echo Prevention)
                # åŒ…æ‹¬ base_msgs å’Œ tail_msgs
                context_ids = [m.id for m in history_msgs if m.id]
                
                found_context = await rag_service.search_context(
                    chat_id, 
                    current_query, 
                    exclude_ids=context_ids
                )
                
                if found_context:
                    rag_context = found_context
                    logger.info(f"RAG: Injected memory for '{current_query[:20]}...'")
        except Exception as e:
            logger.error(f"RAG Search Error: {e}")
    
        if rag_context:
            dynamic_summary += f"\n\n[Relevant Long-term Memories]\n{rag_context}"

        # 3. å‡†å¤‡ç³»ç»Ÿæç¤ºè¯
        # åªè¦æœ«å°¾å­˜åœ¨è¯­éŸ³æˆ–å›¾ç‰‡ï¼Œå°±å¯ç”¨å¯¹åº”çš„å¤šæ¨¡æ€åè®®
        has_v = any(m.message_type == 'voice' for m in tail_msgs)
        has_i = any(m.message_type == 'image' for m in tail_msgs)
    


    # 4. æ£€æŸ¥ä¸Šä¸€è½®è¡¨æƒ…è¿è§„æƒ…å†µ (Reaction Violation Check)
    has_rv = False
    if last_assistant_idx != -1:
        last_assistant_msg = history_msgs[last_assistant_idx]
        # è§£ææ ‡ç­¾ä¸­çš„ react å±æ€§
        react_matches = re.finditer(r'react=["\']([^"\']+)["\']', last_assistant_msg.content)
        for rm in react_matches:
            full_react = rm.group(1).strip()
            emoji_part = full_react.split(":")[0].strip() if ":" in full_react else full_react
            if emoji_part not in sender_service.TG_FREE_REACTIONS:
                has_rv = True
                break
    
    system_content = prompt_builder.build_system_prompt(
        soul_prompt=system_prompt_custom, 
        timezone=timezone, 
        dynamic_summary=dynamic_summary,
        has_voice=has_v,
        has_image=has_i,
        reaction_violation=has_rv
    )
    
    messages = [{"role": "system", "content": system_content}]
    
    # æ—¶åŒºå¤„ç†
    import pytz
    try:
        tz = pytz.timezone(timezone)
    except:
        tz = pytz.UTC

    # 4. å¡«å……åŸºç¡€å†å² (base_msgs)
    for h in base_msgs:
        time_str = "Unknown"
        if h.timestamp:
            try:
                dt = h.timestamp.replace(tzinfo=pytz.UTC) if h.timestamp.tzinfo is None else h.timestamp
                time_str = dt.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S")
            except: pass
        
        msg_id_str = f"MSG {h.message_id}" if h.message_id else "MSG ?"
        msg_type_str = h.message_type.capitalize() if h.message_type else "Text"
        prefix = f"[{msg_id_str}] [{time_str}] [{msg_type_str}] "
        if h.reply_to_content:
            prefix += f'(Reply to "{h.reply_to_content}") '
        messages.append({"role": h.role, "content": prefix + h.content})

    # 5. æ‰«æèšåˆåŒºé—´å†…çš„ Pending å†…å®¹
    pending_images_map = {}
    pending_voices_map = {}
    has_multimodal = False
    for msg in tail_msgs:
        if "[Image: Processing...]" in msg.content or "[Voice: Processing...]" in msg.content:
            has_multimodal = True
            break

    if has_multimodal:
        logger.info(f"Multimodal Batch Triggered. Processing {len(tail_msgs)} tail messages.")
        multimodal_content = []
        
        for msg in tail_msgs:
            # æ ¼å¼åŒ–æ—¶é—´æˆ³
            time_str = "Unknown"
            if msg.timestamp:
                try:
                    dt = msg.timestamp.replace(tzinfo=pytz.UTC) if msg.timestamp.tzinfo is None else msg.timestamp
                    time_str = dt.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S")
                except: pass
            
            msg_id_str = f"MSG {msg.message_id}" if msg.message_id else "MSG ?"
            msg_type_str = msg.message_type.capitalize() if msg.message_type else "Text"
            prefix = f"[{msg_id_str}] [{time_str}] [{msg_type_str}] "

            if msg.message_type == 'image' and msg.file_id and "[Image: Processing...]" in msg.content:
                # æå– Caption 
                caption_text = msg.content.replace("[Image: Processing...]", "").strip()
                
                try:
                    f = await context.bot.get_file(msg.file_id)
                    b = await f.download_as_bytearray()
                    b64 = await media_service.process_image_to_base64(bytes(b))
                    if b64:
                        # å…ˆå‘å›¾æ–‡æè¿°ï¼ˆå¦‚æœ‰ï¼‰
                        display_text = f"{prefix}[Image]"
                        if caption_text:
                            display_text += f" {caption_text}"
                            
                        multimodal_content.append({"type": "text", "text": display_text})
                        multimodal_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
                        pending_images_map[msg.message_id] = msg
                except Exception as e:
                    logger.error(f"Image DL failed: {e}")
                    multimodal_content.append({"type": "text", "text": f"{prefix}[Image Download Failed]"})
            
            elif msg.message_type == 'voice' and msg.file_id and "[Voice: Processing...]" in msg.content:
                try:
                    f = await context.bot.get_file(msg.file_id)
                    b = await f.download_as_bytearray()
                    b64 = await media_service.process_audio_to_base64(bytes(b))
                    if b64:
                        multimodal_content.append({"type": "text", "text": f"{prefix}[Voice]"})
                        multimodal_content.append({"type": "input_audio", "input_audio": {"data": b64, "format": "wav"}})
                        pending_voices_map[msg.message_id] = msg
                except Exception as e:
                    logger.error(f"Voice DL failed: {e}")
                    multimodal_content.append({"type": "text", "text": f"{prefix}[Voice Download Failed]"})
            
            else:
                if msg.content:
                    text_content = msg.content
                    if msg.reply_to_content:
                        prefix += f'(Reply to "{msg.reply_to_content}") '
                    multimodal_content.append({"type": "text", "text": prefix + text_content})

        if multimodal_content:
            messages.append({"role": "user", "content": multimodal_content})
    else:
        # æ™®é€šæ–‡æœ¬æ¨¡å¼ï¼šç›´æ¥è¿½åŠ 
        for h in tail_msgs:
            time_str = "Unknown"
            if h.timestamp:
                try:
                    dt = h.timestamp.replace(tzinfo=pytz.UTC) if h.timestamp.tzinfo is None else h.timestamp
                    time_str = dt.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S")
                except: pass
            
            msg_id_str = f"MSG {h.message_id}" if h.message_id else "MSG ?"
            msg_type_str = h.message_type.capitalize() if h.message_type else "Text"
            prefix = f"[{msg_id_str}] [{time_str}] [{msg_type_str}] "
            if h.reply_to_content:
                prefix += f'(Reply to "{h.reply_to_content}") '
            messages.append({"role": h.role, "content": prefix + h.content})

    # 7. è°ƒç”¨ LLM
    current_temp = safe_float_config(configs.get("temperature", "0.7"), 0.7, 0.0, 2.0)
    
    try:
        client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        # æ³¨æ„: modalities=["text"] åœ¨ audio preview æ¨¡å‹ä¸­é€šå¸¸æ˜¯å¿…é¡»çš„
        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=current_temp,
            max_tokens=4000,
            modalities=["text"] 
        )
        
        if not response.choices or not response.choices[0].message.content:
            await context.bot.send_message(chat_id, "âš ï¸ AI è¿”å›ç©ºå†…å®¹")
            return
            
        reply_content = response.choices[0].message.content.strip()
        logger.info(f"LLM Response: {reply_content[:100]}...")
        
        # 8. è§£æç»“æœå¹¶å›å¡« (Backfill)
        # 8.1 è¯­éŸ³ Transcript (XML + MsgID åŒ¹é…)
        transcript_matches = list(re.finditer(r'<transcript\s+msg_id=["\'](\d+)["\']>(.*?)</transcript>', reply_content, flags=re.DOTALL))
        
        if transcript_matches and pending_voices_map:
            for match in transcript_matches:
                try:
                    msg_id = int(match.group(1))
                    content = match.group(2).strip()
                    
                    if msg_id in pending_voices_map:
                        target_msg = pending_voices_map[msg_id]
                        await history_service.update_message_content_by_file_id(target_msg.file_id, content)
                        logger.info(f"Backfilled transcript for MSG {msg_id}")
                    else:
                        logger.warning(f"Transcript msg_id {msg_id} not found in pending voices map")
                except Exception as e:
                     logger.error(f"Failed to parse transcript match: {e}")

            # æ¸…ç†å›å¤ä¸­çš„ transcript æ ‡ç­¾ï¼Œé¿å…å‘ç»™ç”¨æˆ·
            reply_content = re.sub(r"<transcript.*?>.*?</transcript>", "", reply_content, flags=re.DOTALL).strip()
            
        # 8.2 å›¾ç‰‡ Summary (XML + MsgID åŒ¹é…)
        # åŒ¹é… <img_summary msg_id="123">...</img_summary>
        img_summary_matches = list(re.finditer(r'<img_summary\s+msg_id=["\'](\d+)["\']>(.*?)</img_summary>', reply_content, flags=re.DOTALL))
        
        if img_summary_matches and pending_images_map:
            for match in img_summary_matches:
                try:
                    msg_id = int(match.group(1))
                    content = match.group(2).strip()
                    
                    if msg_id in pending_images_map:
                        target_msg = pending_images_map[msg_id]
                        final_summary = f"[Image Summary: {content}]" 
                        await history_service.update_message_content_by_file_id(target_msg.file_id, final_summary)
                        logger.info(f"Backfilled summary for MSG {msg_id}")
                    else:
                        logger.warning(f"Image summary msg_id {msg_id} not found in pending images map")
                except Exception as e:
                    logger.error(f"Failed to parse image summary match: {e}")
            
            # æ¸…ç†å›å¤ä¸­çš„ img_summary æ ‡ç­¾
            reply_content = re.sub(r"<img_summary.*?>.*?</img_summary>", "", reply_content, flags=re.DOTALL).strip()
            
        if not reply_content:
            reply_content = "<chat>...</chat>" # å…œåº•

        # 9. å‘é€å›å¤
        # åªè¦åŒ…å«è¯­éŸ³è¾“å…¥ï¼Œä¸€å¾‹é‡‡ç”¨è¯­éŸ³å“åº”
        reply_mtype = 'voice' if has_v else 'text'
        
        await sender_service.send_llm_reply(
            chat_id=chat_id,
            reply_content=reply_content,
            context=context,
            history_msgs=history_msgs,
            message_type=reply_mtype
        )


    except Exception as e:
        logger.error(f"API Call failed: {e}")
        # --- æ±¡æŸ“æ¸…ç†é€»è¾‘ ---
        # å¦‚æœå¤„ç†å¤±è´¥ï¼Œåˆ é™¤å½“å‰æ‰¹æ¬¡ä¸­å¤„äº "Processing..." çŠ¶æ€çš„å ä½æ¶ˆæ¯ï¼Œé˜²æ­¢æ±¡æŸ“ä¸Šä¸‹æ–‡
        try:
            async for session in get_db_session():
                # å¯»æ‰¾å½“å‰æ‰¹æ¬¡ä¸­æ‰€æœ‰å¸¦ Processing æ ‡è¯†çš„æ¶ˆæ¯ ID
                pending_ids = [m.id for m in tail_msgs if "[Image: Processing...]" in m.content or "[Voice: Processing...]" in m.content]
                if pending_ids:
                    await session.execute(delete(History).where(History.id.in_(pending_ids)))
                    await session.commit()
                    logger.info(f"Context Cleanup: Removed {len(pending_ids)} pending placeholder(s) due to API failure.")
        except Exception as cleanup_err:
            logger.error(f"Failed to cleanup pending placeholders: {cleanup_err}")

        # å¼ºåˆ¶é€šçŸ¥ç®¡ç†å‘˜ (ç§èŠæ¨é€)
        try:
            error_msg = (
                f"ğŸš¨ <b>API Call Failed</b>\n\n"
                f"ä¼šè¯ ID: <code>{chat_id}</code>\n"
                f"é”™è¯¯è¯¦æƒ…: <code>{e}</code>\n\n"
                f"ğŸ’¡ <i>ä¸Šä¸‹æ–‡æ±¡æŸ“å·²è‡ªåŠ¨æ¸…ç†ï¼Œè¯·æ£€æŸ¥ API ä½™é¢æˆ–ç½‘ç»œç¯å¢ƒã€‚</i>"
            )
            await context.bot.send_message(settings.ADMIN_USER_ID, error_msg, parse_mode='HTML')
        except Exception as notify_err:
            logger.error(f"Failed to notify admin privately: {notify_err}")


async def process_reaction_update(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†è¡¨æƒ…å›åº”æ›´æ–°"""
    reaction = update.message_reaction
    if not reaction:
        return
        
    chat = reaction.chat
    user = reaction.user
    message_id = reaction.message_id
    
    if chat.type == constants.ChatType.PRIVATE:
        return
    if not await access_service.is_whitelisted(chat.id):
        return
        
    if user and user.id == context.bot.id:
        return

    emojis = []
    for react in reaction.new_reaction:
        if hasattr(react, 'emoji'):
            emojis.append(react.emoji)
        elif hasattr(react, 'custom_emoji_id'):
            emojis.append('[CustomEmoji]')
            
    if not emojis:
        content = f"[System Info] {user.first_name if user else 'User'} removed reaction from [MSG {message_id}]"
    else:
        emoji_str = "".join(emojis)
        content = f"[System Info] {user.first_name if user else 'User'} reacted {emoji_str} to [MSG {message_id}]"

    logger.info(f"REACTION [{chat.id}]: {content}")
    
    await history_service.add_message(
        chat_id=chat.id,
        role="system",
        content=content
    )

lazy_sender.set_callback(generate_response)
